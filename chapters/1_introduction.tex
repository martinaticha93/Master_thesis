\chapter{Introduction}

The task of person re-identification in a video (person re-ID) aims to re-identify a person that has already been recorded by a camera. It has been a subject of research for many years, since information usually used for identifying a person (mainly its face) is not reliably available, due to the person's rotation or insufficient resolution of the camera.

There is a vast variety of practical applications of person re-ID systems in both commercial and law enforcement areas. Surveillance systems are nowadays widely deployed for public safety. Hence, there is a high demand on technologies that can automatically detect strange behavior patterns in frequented places with high-security risks like airports, banks or large cultural events or in areas with strong security restrictions, e.g., embassies and laboratories.

The reason why this problem is challenging is that the surveillance cameras are located in a fixed position while the recorded people are walking at various distances from the cameras. Hence, in most cases, the resolution of the video is not sufficient for recognizing details like faces. Apart from this, there are other issues like illumination changes, occlusions, pose variations or change of clothes that make person re-ID task difficult.

In the early days, the algorithms to person re-ID were based on hand-crafted features and evaluated on small data sets. In recent years, deep learning systems utilizing newly available large-scale data sets emerged.    

Most of the current approaches assume that people going across the surveillance camera have not changed their appearance significantly. This condition restricts the person re-ID to a short-term event. However, in many places, people are likely to reappear after a long period when they have, for instance, changed their clothes. For these cases, short-term person re-ID approaches that rely on the visual aspects of the recorded people do not suffice.

To overcome this issue, an approach which ignores the person's appearance needs to be used. One of the possibilities is to construct a model which focuses on the gait of the recorded people. To achieve this, we can first extract features describing the movement of the observed person from the raw videos and feed the model with the extracted features only. Another option is to use the original videos directly but to eliminate the visual features in the initial steps. 

In this thesis, we try three approaches to do so. In the first one, we transform each frame in the video sequence into silhouettes on a white background. While this approach hides information such as the color of the clothing, some information such as the shape of the clothes the persons are wearing still remains. This can possibly confuse the model once the observed identity changes their clothes. For instance, the silhouette of a person in jeans is different from the one wearing a dress. In the second approach, we locate the joints of the observed people in each frame of the video sequence and use their position in time as the only input to the model. This way, all the information except for the movement characteristics of the walking people is dropped before the training. The third method is then the combination of both previous methods. We first transform each image frame into contours, and then we mark the skeletons constructed by joints connections on the silhouette of the observed identity. This way, the model is provided with more information and can decide itself which of them to use.